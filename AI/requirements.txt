# =============================================================================
#                     SIGMA GPT AI SERVICE - REQUIREMENTS
# =============================================================================
#
# ðŸ“š HOW TO INSTALL:
# -----------------
#     cd /path/to/AI
#     pip install -r requirements.txt
#
# ðŸ“Œ WHAT IS requirements.txt?
# ---------------------------
# This file lists all Python packages (libraries) our project needs.
# pip reads this file and installs everything.
#
# Format: package_name>=minimum_version
#   - >= means "at least this version"
#   - == means "exactly this version"
#
# =============================================================================

# =============================================================================
#                     FASTAPI & SERVER
# =============================================================================

fastapi>=0.115.5
# ðŸ“– FastAPI - The web framework for building our API
# From: https://fastapi.tiangolo.com/
# Why: Creates HTTP endpoints that Frontend/Backend can call
# Used in: main.py - to create our API server

uvicorn>=0.32.1
# ðŸ“– Uvicorn - ASGI server that runs FastAPI
# From: https://www.uvicorn.org/
# Why: FastAPI is just code, uvicorn actually serves it
# Used in: main.py - uvicorn.run(app, ...)
# Think of it as: FastAPI = recipe, Uvicorn = the chef

python-dotenv>=1.0.1
# ðŸ“– Python-dotenv - Loads environment variables from .env file
# From: https://pypi.org/project/python-dotenv/
# Why: Store sensitive data (API keys) in .env, not in code
# Used in: main.py - load_dotenv()
# ðŸ”— Your notes used this in every file!

python-multipart>=0.0.9
# ðŸ“– Python-multipart - Handles file uploads in FastAPI
# From: https://github.com/andrew-d/python-multipart
# Why: Needed for UploadFile to work (PDF, audio, image uploads)
# Used in: rag_service.py, tools_service.py

# =============================================================================
#                     OPENAI
# =============================================================================

openai>=1.60.2
# ðŸ“– OpenAI - Official Python client for OpenAI API
# From: https://github.com/openai/openai-python
# Why: Call GPT models (chat), Whisper (speech-to-text), embeddings
# Used in: All services - client = OpenAI()
# ðŸ”— Your notes: client.chat.completions.create(...)

# =============================================================================
#                     LANGCHAIN
# =============================================================================

langchain-openai>=0.3.6,<1.0.0
# ðŸ“– LangChain-OpenAI - LangChain integration with OpenAI
# From: https://python.langchain.com/
# Why: Provides OpenAIEmbeddings for vector embeddings
# Used in: rag_service.py - embedding_model = OpenAIEmbeddings(...)
# ðŸ”— Your notes (04-RAG/indexing.py): embedding_model = OpenAIEmbeddings(...)
# ðŸ“Œ IMPORTANT: Pinned to <1.0.0 for compatibility with langchain-qdrant 0.1.4

langchain-qdrant==0.1.4
# ðŸ“– LangChain-Qdrant - LangChain integration with Qdrant vector DB
# From: https://python.langchain.com/docs/integrations/vectorstores/qdrant
# Why: Stores and searches vectors in Qdrant
# Used in: rag_service.py - QdrantVectorStore.from_documents(...)
# ðŸ”— Your notes (04-RAG/indexing.py): QdrantVectorStore.from_documents(...)
# ðŸ“Œ IMPORTANT: Pinned to 0.1.4 - newer versions (1.x) break compatibility with existing Qdrant data!

langchain-text-splitters>=0.3.0,<1.0.0
# ðŸ“– LangChain Text Splitters - For chunking documents
# From: LangChain package
# Why: Split long documents into smaller chunks for embedding
# Used in: rag_service.py - RecursiveCharacterTextSplitter(...)
# ðŸ”— Your notes (04-RAG/indexing.py): RecursiveCharacterTextSplitter(...)

langchain>=0.3.0,<1.0.0
# ðŸ“– LangChain - Core LangChain library
# From: https://python.langchain.com/
# Why: Provides base classes and utilities for AI workflows
# Used in: agent_service.py, travel_graph.py

langchain-mongodb>=0.6.1
# ðŸ“– LangChain MongoDB - MongoDB integration for LangChain
# From: LangChain package
# Why: Store and retrieve data from MongoDB within LangChain workflows
# Used in: agent_service.py - for persistent memory

# =============================================================================
#                     LANGGRAPH (AI Workflows)
# =============================================================================

langgraph>=0.6.0
# ðŸ“– LangGraph - Framework for multi-step AI workflows
# From: https://langchain-ai.github.io/langgraph/
# Why: Build complex AI agents with state management
# Used in: travel_graph.py (8-node), solo_trip_graph.py (11-node)
# ðŸ”— Your notes (07-LangGraph): StateGraph, START, END

langgraph-checkpoint-mongodb>=0.2.0
# ðŸ“– LangGraph MongoDB Checkpoint - Persist workflow state in MongoDB
# From: LangGraph package
# Why: Save and resume AI workflows (crucial for Human-in-the-Loop)
# Used in: solo_trip_graph.py - MongoDBSaver for HITL

tavily-python>=0.5.0
# ðŸ“– Tavily - AI-powered web search
# From: https://tavily.com/
# Why: Real-time web search for AI agents
# Used in: tools_service.py, travel_graph.py
# ðŸ“Œ Set TAVILY_API_KEY in .env file

# =============================================================================
#                     VECTOR DATABASE
# =============================================================================

qdrant-client>=1.10.1,<1.12.0
# ðŸ“– Qdrant Client - Python client for Qdrant vector database
# From: https://github.com/qdrant/qdrant-client
# Why: Communicate with Qdrant server for vector storage/search
# Used in: rag_service.py - for filtering queries
# ðŸ”— Your notes used Qdrant at http://localhost:6333
# ðŸ“Œ IMPORTANT: Pinned to <1.12.0 for compatibility with langchain-qdrant 0.1.4
#    Newer versions have Collection objects that break boolean testing

# =============================================================================
#                     PDF PROCESSING
# =============================================================================

pypdf>=5.1.0
# ðŸ“– PyPDF - Pure Python PDF library
# From: https://github.com/py-pdf/pypdf
# Why: Extract text from PDF files
# Used in: rag_service.py - PdfReader(BytesIO(content))
# ðŸ”— Your notes used PyPDFLoader (same concept, different wrapper)

# =============================================================================
#                     HTTP REQUESTS & SEARCH
# =============================================================================

requests>=2.32.0
# ðŸ“– Requests - HTTP library for Python
# From: https://requests.readthedocs.io/
# Why: Make HTTP requests (web search, external APIs)
# Used in: agent_service.py - requests.get(search_url)
# ðŸ”— Your notes (03-Agents/main.py): requests.get(weather_url)

exa_py>=2.0.1
# ðŸ“– Exa.ai - AI-powered semantic search engine
# From: https://docs.exa.ai/
# Why: Secondary search engine with semantic understanding
# Used in: tools_service.py - exa_search()
# ðŸ“Œ Better for research-heavy queries, understands intent
# Set EXA_API_KEY in .env file

# =============================================================================
#                     REDIS (Optional - for persistent memory)
# =============================================================================

redis>=7.0.1
# ðŸ“– Redis - Python client for Redis database
# From: https://github.com/redis/redis-py
# Why: Store conversation memory persistently
# Used in: agent_service.py - for session memory
# ðŸ”— Your notes (advanced_rag/queue/connection.py): from redis import Redis

pymongo>=4.0.0
# ðŸ“– PyMongo - Official MongoDB driver for Python
# From: https://pymongo.readthedocs.io/
# Why: Store LangGraph checkpoints (conversation state) in MongoDB
# Used in: agent_service.py - MongoDBCheckpointer class
# ðŸ”— Your notes (07-LangGraph/graph.py): 
#     from langgraph.checkpoint.mongodb import MongoDBSaver
#     with MongoDBSaver.from_conn_string(DB_URI) as mongo_checkpointer:
# ðŸ“Œ We implement the same checkpointing pattern using pymongo directly!

# =============================================================================
#                     OCR (IMAGE TO TEXT)
# =============================================================================

pytesseract>=0.3.10
# ðŸ“– Pytesseract - Python wrapper for Tesseract OCR
# From: https://github.com/madmaze/pytesseract
# Why: Extract text from images (screenshots, scanned docs)
# Used in: tools_service.py - pytesseract.image_to_string(...)
# ðŸ“Œ Requires Tesseract installed on system:
#    macOS: brew install tesseract
#    Ubuntu: sudo apt-get install tesseract-ocr

pdf2image>=1.17.0
# ðŸ“– PDF2Image - Convert PDF pages to images
# From: https://github.com/Belval/pdf2image
# Why: OCR for scanned PDFs (convert page to image, then OCR)
# Used in: rag_service.py - convert_from_bytes(...)
# ðŸ“Œ Requires Poppler installed on system:
#    macOS: brew install poppler
#    Ubuntu: sudo apt-get install poppler-utils

Pillow>=10.4.0
# ðŸ“– Pillow (PIL) - Python Imaging Library
# From: https://pillow.readthedocs.io/
# Why: Image processing for OCR preprocessing
# Used in: tools_service.py - Image.open(...), ImageOps, ImageFilter
# ðŸ“Œ This is a MUST for any image processing in Python


# =============================================================================
#                     SUMMARY
# =============================================================================
#
# CORE (Required):
#   - fastapi, uvicorn: Web server
#   - openai: AI models (GPT, Whisper)
#   - python-dotenv: Environment variables
#
# RAG (For PDF Q&A):
#   - langchain-openai: Embeddings
#   - langchain-qdrant: Vector storage
#   - langchain-text-splitters: Chunking
#   - qdrant-client: Vector DB client
#   - pypdf: PDF reading
#
# TOOLS (Optional but useful):
#   - requests: HTTP calls
#   - redis: Persistent memory
#   - pytesseract, pdf2image, Pillow: OCR
#
# =============================================================================
